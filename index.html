<!DOCTYPE html>
<html lang="en"><head>  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Class Project
  | Fall 2020: CS 4476 Computer Vision</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->  
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>
  
<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name --> 
<h1>Mask Detection</h1> 
<span style="font-size: 20px; line-height: 1.5em;"><strong>Rithik Gavvala, Mithil Verma, Nandin Padheriya, Vamsi Desu, and Sahiti Baddula</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2020 CS 4476 Computer Vision: Class Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Georgia Tech</span>
<hr>

<!-- Goal -->
<h3>Abstract</h3>

One or two sentences on the motivation behind the problem you are solving. One or two sentences describing the approach you took. One or two sentences on the main result you obtained.
<br><br>
<!-- figure -->
<h3>Teaser figure</h3>
<br><br>
<!-- Main Illustrative Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="teaser.png">
</div>

<br><br>
<!-- Introduction -->
<h3>Introduction</h3>
During the COVID pandemic, many health organizations have urged people to wear facial coverings or masks to prevent the spread of coronavirus. This has led to many offices and other establishments that require in-person activity to enforce wearing masks. Our system will enable establishments to determine whether a person is wearing a mask. To solve this problem, we will be using convolutional neural networks, which consists of multiple of convolutional layers, to classify those who are wearing masks and those who are not.
<br><br>
<!-- Approach -->
<h3>Approach</h3>
There are two main technical approaches we can take. First, we can implement a convolutional neural network as our first model using Python and Numpy. The second approach is to produce vector features from scale-invariant feature  transform, gray level co-occurrence matrix,  and local binary pattern. These are various feature extractors that we can use for classification. Afterwards, for each output from each of the feature extractors ,we will split this into more experiments with principal component analysis. We will have three experiments with using PCA and without using PCA. Lastly, we will use the features selected previously and use SVM to fit the data. Then, we will use our predicting set and predict the images and evaluate based on accuracy, precision, and recall.     


<br><br>
<!-- Results -->
<h3>Experiments and results</h3>
When we first retrieved the data, there were roughly 6 different columns, where the name represented the name of the image in the training set, x1 through y2 represented the position/coordinates of the person's face who was wearing the mask, and the classname printed symbols that depicted whether the person was wearing a mask, not wearing a mask, wearing a mask incorrectly etc. In order to start on cleaning the data we first decided to  change the values in the image name column so that the values were now pointing to the actual file path of the image. Thus, calling and loading image would be much simpler as it would simply take a query to the name column in order to read in an image. <br>
<br>
Next we noticed that many of the image names in the data frame were being repeated. The reason for this was because many images had many different people present in them. Thus, each separate image entry had coordinates for a separate person wearing a separate mask, in order to simplify the data frame, we thus, went through the entries and appended the coordinates present in the same image, into one entry, under a column called commonPosition. By doing so, it was a lot easier for us to reference one image at a time since now, each row simply catered to the features of one individual image. Since we had this new accumulation of coordinate points, we were able to drop our x1 through y2 columns. <br><br>

Lastly, we saw that the dataset had a random array of labels foreach image. Even though there were labels such as "face_with_mask_incorrect", "face_with_mask", and "gas_mask" (which were somewhat related to our topic since they still covered the nose and mouth) there were also labels such as "mask_colorful" and "hat" which did not make any sense to us. Thus, we kept it simple and bundled all labels that were of use to us into one collective label called "face_with_mask" and certain other ones into a category known as "mask_incorrect". Simplifying the labels up tot his point made it a lot easier for us to go ahead and run our Sequencer model in order to properly train our dataset and later on fit it to images we would try to predict. <br>

<br><br>

<!-- Main Results Figure --> 
<div>
  <div style="text-align: center;">
    <img style="height: 200px;" alt="" src="barchart.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 200px;" alt="" src="table.png">
      </div>
      <div style="text-align: center;">
        <img style="height: 200px;" alt="" src="table2.png">
        </div>

</div>

<br><br>

<!-- Results -->
<h3>Qualitative results</h3>
<br><br>

<!-- Main Results Figure --> 
<div style="text-align: center;">
<img style="height: 300px;" alt="" src="boundingbox.png">
</div>
<br><br>




  <hr>
  <footer> 
  <p>©Rithik Gavvala, Mithil Verma, Nandin Padheriya, Vamsi Desu, and Sahiti Baddula </p>
  </footer>
</div>
</div>

<br><br>

</body></html>